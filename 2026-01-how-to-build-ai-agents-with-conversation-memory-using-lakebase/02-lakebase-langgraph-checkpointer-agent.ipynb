{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e411b194-dd96-4131-ab8a-5b8ba9914df9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U -qqqq databricks-langchain[memory] uv databricks-agents mlflow-skinny[databricks]\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0550d280-c496-4a2e-9bdc-814a428dee43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43ec4cb9-6706-473c-8cce-ad05defa9f63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Mosaic AI Agent Framework: Author and deploy a Stateful Agent using Databricks Lakebase and LangGraph\n",
    "This notebook demonstrates how to build a stateful agent using the Mosaic AI Agent Framework and LangGraph, with Lakebase as the agent’s durable memory and checkpoint store. In this notebook, you will:\n",
    "1. Author a Stateful Agent graph with LakeBase (the new Postgres database in Databricks) and Langgraph to manage state using thread ids in a Databricks Agent \n",
    "2. Wrap the LangGraph agent with MLflow ChatAgent to ensure compatibility with Databricks features\n",
    "3. Test the agent's behavior locally\n",
    "4. Register model to Unity Catalog, log and deploy the agent for use in apps and Playground\n",
    "\n",
    "We use [PostgresSaver in Langgraph](https://api.python.langchain.com/en/latest/checkpoint/langchain_postgres.checkpoint.PostgresSaver.html) to open a connection with our Lakebase, pass it into the checkpoint and pass that into the LangGraph Agent\n",
    "\n",
    "## Why use Lakebase?\n",
    "Stateful agents need a place to persist, resume, and inspect their work. Lakebase provides a managed, UC-governed store for agent state:\n",
    "- Durable, resumable state. Automatically capture threads, intermediate checkpoints, tool outputs, and node state after each graph step—so you can resume, branch, or replay any point in time.\n",
    "- Queryable & observable. Because state lands in the Lakehouse, you can use SQL (or notebooks) to audit conversations and build upon other Databricks functionality like dashboards\n",
    "- Governed by Unity Catalog. Apply data permissions, lineage, and auditing to AI state, just like any other table.\n",
    "\n",
    "## What are Stateful Agents?\n",
    "Unlike stateless LLM calls, a stateful agent keeps and reuses context across steps and sessions. Each new conversation is tracked with a thread ID, which represents the logical task or dialogue stream. This way, you can pick up an existing thread and continue the conversation with your Agent.\n",
    "\n",
    "## Prerequisites\n",
    "- Create a Lakebase instance, see Databricks documentation ([AWS](https://docs.databricks.com/aws/en/oltp/create/) | [Azure](https://learn.microsoft.com/en-us/azure/databricks/oltp/create/)). \n",
    "- You can create a Lakebase instance by going to SQL Warehouses -> Lakebase Postgres -> Create database instance. You will need to retrieve values from the \"Connection details\" section of your Lakebase to fill out this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb3511ac-953a-4707-bea3-be4376f4ed42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(name=\"catalog\", defaultValue=\"\", label=\"catalog\")\n",
    "dbutils.widgets.text(name=\"schema\", defaultValue=\"\", label=\"schema\")\n",
    "dbutils.widgets.text(name=\"model\", defaultValue=\"\", label=\"model\")\n",
    "dbutils.widgets.text(\n",
    "    name=\"DATABRICKS_CLIENT_ID\", defaultValue=\"\", label=\"DATABRICKS_CLIENT_ID\"\n",
    ")\n",
    "dbutils.widgets.text(\n",
    "    name=\"DATABRICKS_CLIENT_SECRET\", defaultValue=\"\", label=\"DATABRICKS_CLIENT_SECRET\"\n",
    ")\n",
    "dbutils.widgets.text(name=\"secret_scope\", defaultValue=\"\", label=\"secret_scope\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c7a72f0-bc6e-489d-8ec3-f4d7ba4238aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalog = dbutils.widgets.get(\"catalog\")\n",
    "schema = dbutils.widgets.get(\"schema\")\n",
    "model = dbutils.widgets.get(\"model\")\n",
    "# LLM_ENDPOINT = dbutils.widgets.get(\"foundation_model\")\n",
    "assert (\n",
    "    len(catalog) > 0 and len(schema) > 0 and len(model) > 0\n",
    "), \"Please provide a valid catalog, schema, and model name\"\n",
    "three_tiered_model_name = f\"{catalog}.{schema}.{model}\"\n",
    "print(f\"{three_tiered_model_name=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a036ef50-66ac-45ec-b678-64d4c3fb3a5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "\n",
    "w = WorkspaceClient()\n",
    "\n",
    "DATABRICKS_HOST = w.config.host\n",
    "\n",
    "secret_scope_name = dbutils.widgets.get(\"secret_scope\")\n",
    "\n",
    "# if needed create a secret scope\n",
    "if secret_scope_name != \"dbdemos\":\n",
    "    w.secrets.create_scope(scope=secret_scope_name)\n",
    "else:\n",
    "    print(f\"Using existing secret scope: {secret_scope_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "632ff6d6-902c-478e-8d6f-2c8e743b6d31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if dbutils.widgets.get(\"DATABRICKS_CLIENT_ID\") == \"\":\n",
    "    print(\"no DATABRICKS_CLIENT_ID is provided\")\n",
    "else:\n",
    "    w.secrets.put_secret(\n",
    "        scope=secret_scope_name,\n",
    "        key=\"DATABRICKS_CLIENT_ID\",\n",
    "        string_value=dbutils.widgets.get(\"DATABRICKS_CLIENT_ID\"),\n",
    "    )\n",
    "if dbutils.widgets.get(\"DATABRICKS_CLIENT_SECRET\") == \"\":\n",
    "    print(\"no DATABRICKS_CLIENT_ID is provided\")\n",
    "else:\n",
    "    w.secrets.put_secret(\n",
    "        scope=secret_scope_name,\n",
    "        key=\"DATABRICKS_CLIENT_SECRET\",\n",
    "        string_value=dbutils.widgets.get(\"DATABRICKS_CLIENT_SECRET\"),\n",
    "    )\n",
    "w.secrets.put_secret(\n",
    "    scope=secret_scope_name, key=\"DATABRICKS_HOST\", string_value=DATABRICKS_HOST\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea052166-1d1a-44c3-9408-07a16b1bd28e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# os.environ[\"DATABRICKS_CLIENT_ID\"] = dbutils.secrets.get(\n",
    "#     scope=secret_scope_name, key=\"DATABRICKS_CLIENT_ID\"\n",
    "# )\n",
    "# os.environ[\"DATABRICKS_CLIENT_SECRET\"] = dbutils.secrets.get(\n",
    "#     scope=secret_scope_name, key=\"DATABRICKS_CLIENT_SECRET\"\n",
    "# )\n",
    "\n",
    "# os.unsetenv(\"DATABRICKS_CLIENT_ID\")\n",
    "# os.unsetenv(\"DATABRICKS_CLIENT_SECRET\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12bb5e31-3252-4dc6-92e9-7013f1e83d43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Lakebase Config\n",
    "- Enable Postgres native role login\n",
    "- Might need to wait a few min for pg roles to apply\n",
    "- Create new catalog with PostgreSQL Database: `databricks_postgres` schema off lakebase instance for querying purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2caaac13-e6d5-4475-8ea9-b8cb3abd21ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# First-time checkpoint table setup\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks_langchain import CheckpointSaver\n",
    "\n",
    "# --- TODO: Fill in Lakebase instance name ---\n",
    "INSTANCE_NAME = \"<INSERT LAKEBASE NAME>\"\n",
    "\n",
    "# Create tables if missing\n",
    "with CheckpointSaver(instance_name=INSTANCE_NAME) as saver:\n",
    "    saver.setup()  # sets up checkpoint tables\n",
    "    print(\"✅ Checkpoint tables are ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ec24de0-62ab-4ac7-a7de-17b15cff0e64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile agent.py\n",
    "import logging\n",
    "import os\n",
    "import uuid\n",
    "from typing import Annotated, Any, Generator, Optional, Sequence, TypedDict\n",
    "\n",
    "import mlflow\n",
    "from databricks_langchain import (\n",
    "    ChatDatabricks,\n",
    "    UCFunctionToolkit,\n",
    "    CheckpointSaver,\n",
    ")\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from langchain_core.messages import AIMessage, AIMessageChunk, AnyMessage\n",
    "from langchain_core.runnables import RunnableConfig, RunnableLambda\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt.tool_node import ToolNode\n",
    "from mlflow.pyfunc import ResponsesAgent\n",
    "from mlflow.types.responses import (\n",
    "    ResponsesAgentRequest,\n",
    "    ResponsesAgentResponse,\n",
    "    ResponsesAgentStreamEvent,\n",
    "    output_to_responses_items_stream,\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=os.getenv(\"LOG_LEVEL\", \"INFO\"))\n",
    "\n",
    "############################################\n",
    "# Define your LLM endpoint and system prompt\n",
    "############################################\n",
    "# TODO: Replace with your model serving endpoint\n",
    "LLM_ENDPOINT_NAME = \"databricks-gpt-5-2\"\n",
    "\n",
    "# TODO: Update with your system prompt\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "    You are an cybersecurity assistant.\n",
    "    You are given a task and you must complete it.\n",
    "    Use the following routine to support the customer.\n",
    "    # Routine:\n",
    "    1. Provide the get_cyber_threat_info tool the type of threat being asked about.\n",
    "    2. Use the source ip address provided in step 1 as input for the get_user_info tool to retrieve user specific info.\n",
    "    Use the following tools to complete the task:\n",
    "    {tools}\"\"\"\n",
    "\n",
    "############################################\n",
    "# Lakebase configuration\n",
    "############################################\n",
    "# TODO: Fill in Lakebase instance name\n",
    "LAKEBASE_INSTANCE_NAME = \"<INSERT LAKEBASE NAME>\"\n",
    "\n",
    "###############################################################################\n",
    "## Define tools for your agent,enabling it to retrieve data or take actions\n",
    "## beyond text generation\n",
    "## To create and see usage examples of more tools, see\n",
    "## https://docs.databricks.com/en/generative-ai/agent-framework/agent-tool.html\n",
    "###############################################################################\n",
    "tools = []\n",
    "\n",
    "# Example UC tools; add your own as needed\n",
    "UC_TOOL_NAMES: list[str] = [\n",
    "    \"catalog.schema.get_cyber_threat_info\",\n",
    "    \"cataog.schema.get_user_info\",\n",
    "]\n",
    "if UC_TOOL_NAMES:\n",
    "    uc_toolkit = UCFunctionToolkit(function_names=UC_TOOL_NAMES)\n",
    "    tools.extend(uc_toolkit.tools)\n",
    "\n",
    "# Use Databricks vector search indexes as tools\n",
    "# See https://docs.databricks.com/en/generative-ai/agent-framework/unstructured-retrieval-tools.html#locally-develop-vector-search-retriever-tools-with-ai-bridge\n",
    "# List to store vector search tool instances for unstructured retrieval.\n",
    "VECTOR_SEARCH_TOOLS = []\n",
    "\n",
    "# To add vector search retriever tools,\n",
    "# use VectorSearchRetrieverTool and create_tool_info,\n",
    "# then append the result to TOOL_INFOS.\n",
    "# Example:\n",
    "# VECTOR_SEARCH_TOOLS.append(\n",
    "#     VectorSearchRetrieverTool(\n",
    "#         index_name=\"\",\n",
    "#         # filters=\"...\"\n",
    "#     )\n",
    "# )\n",
    "\n",
    "tools.extend(VECTOR_SEARCH_TOOLS)\n",
    "\n",
    "#####################\n",
    "## Define agent logic\n",
    "#####################\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[AnyMessage], add_messages]\n",
    "    custom_inputs: Optional[dict[str, Any]]\n",
    "    custom_outputs: Optional[dict[str, Any]]\n",
    "\n",
    "\n",
    "class LangGraphResponsesAgent(ResponsesAgent):\n",
    "    \"\"\"Stateful agent using ResponsesAgent with pooled Lakebase checkpointing.\"\"\"\n",
    "\n",
    "    def __init__(self, lakebase_config: dict[str, Any]):\n",
    "        self.workspace_client = WorkspaceClient()\n",
    "\n",
    "        self.model = ChatDatabricks(endpoint=LLM_ENDPOINT_NAME)\n",
    "        self.system_prompt = SYSTEM_PROMPT\n",
    "        self.model_with_tools = self.model.bind_tools(tools) if tools else self.model\n",
    "\n",
    "    def _create_graph(self, checkpointer: Any):\n",
    "        def should_continue(state: AgentState):\n",
    "            messages = state[\"messages\"]\n",
    "            last_message = messages[-1]\n",
    "            if isinstance(last_message, AIMessage) and last_message.tool_calls:\n",
    "                return \"continue\"\n",
    "            return \"end\"\n",
    "\n",
    "        preprocessor = (\n",
    "            RunnableLambda(\n",
    "                lambda state: [{\"role\": \"system\", \"content\": self.system_prompt}]\n",
    "                + state[\"messages\"]\n",
    "            )\n",
    "            if self.system_prompt\n",
    "            else RunnableLambda(lambda state: state[\"messages\"])\n",
    "        )\n",
    "        model_runnable = preprocessor | self.model_with_tools\n",
    "\n",
    "        def call_model(state: AgentState, config: RunnableConfig):\n",
    "            response = model_runnable.invoke(state, config)\n",
    "            return {\"messages\": [response]}\n",
    "\n",
    "        workflow = StateGraph(AgentState)\n",
    "        workflow.add_node(\"agent\", RunnableLambda(call_model))\n",
    "\n",
    "        if tools:\n",
    "            workflow.add_node(\"tools\", ToolNode(tools))\n",
    "            workflow.add_conditional_edges(\n",
    "                \"agent\", should_continue, {\"continue\": \"tools\", \"end\": END}\n",
    "            )\n",
    "            workflow.add_edge(\"tools\", \"agent\")\n",
    "        else:\n",
    "            workflow.add_edge(\"agent\", END)\n",
    "\n",
    "        workflow.set_entry_point(\"agent\")\n",
    "        return workflow.compile(checkpointer=checkpointer)\n",
    "\n",
    "    def _get_or_create_thread_id(self, request: ResponsesAgentRequest) -> str:\n",
    "        \"\"\"Get thread_id from request or create a new one.\n",
    "\n",
    "        Priority:\n",
    "        1. Use thread_id from custom_inputs if present\n",
    "        2. Use conversation_id from chat context if available\n",
    "        3. Generate a new UUID\n",
    "\n",
    "        Returns:\n",
    "            thread_id: The thread identifier to use for this conversation\n",
    "        \"\"\"\n",
    "        ci = dict(request.custom_inputs or {})\n",
    "\n",
    "        if \"thread_id\" in ci:\n",
    "            return ci[\"thread_id\"]\n",
    "\n",
    "        # using conversation id from chat context as thread id\n",
    "        # https://mlflow.org/docs/latest/api_reference/python_api/mlflow.types.html#mlflow.types.agent.ChatContext\n",
    "        if request.context and getattr(request.context, \"conversation_id\", None):\n",
    "            return request.context.conversation_id\n",
    "\n",
    "        # Generate new thread_id\n",
    "        return str(uuid.uuid4())\n",
    "\n",
    "    def predict(self, request: ResponsesAgentRequest) -> ResponsesAgentResponse:\n",
    "        outputs = [\n",
    "            event.item\n",
    "            for event in self.predict_stream(request)\n",
    "            if event.type == \"response.output_item.done\"\n",
    "        ]\n",
    "        return ResponsesAgentResponse(\n",
    "            output=outputs, custom_outputs=request.custom_inputs\n",
    "        )\n",
    "\n",
    "    def predict_stream(\n",
    "        self, request: ResponsesAgentRequest\n",
    "    ) -> Generator[ResponsesAgentStreamEvent, None, None]:\n",
    "        thread_id = self._get_or_create_thread_id(request)\n",
    "        ci = dict(request.custom_inputs or {})\n",
    "        ci[\"thread_id\"] = thread_id\n",
    "        request.custom_inputs = ci\n",
    "\n",
    "        # Convert incoming Responses messages to ChatCompletions format\n",
    "        # LangChain will automatically convert from ChatCompletions to LangChain format\n",
    "        cc_msgs = self.prep_msgs_for_cc_llm([i.model_dump() for i in request.input])\n",
    "        langchain_msgs = cc_msgs\n",
    "        checkpoint_config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "        with CheckpointSaver(instance_name=LAKEBASE_INSTANCE_NAME) as checkpointer:\n",
    "            graph = self._create_graph(checkpointer)\n",
    "\n",
    "            for event in graph.stream(\n",
    "                {\"messages\": langchain_msgs},\n",
    "                checkpoint_config,\n",
    "                stream_mode=[\"updates\", \"messages\"],\n",
    "            ):\n",
    "                if event[0] == \"updates\":\n",
    "                    for node_data in event[1].values():\n",
    "                        if len(node_data.get(\"messages\", [])) > 0:\n",
    "                            yield from output_to_responses_items_stream(\n",
    "                                node_data[\"messages\"]\n",
    "                            )\n",
    "                elif event[0] == \"messages\":\n",
    "                    try:\n",
    "                        chunk = event[1][0]\n",
    "                        if isinstance(chunk, AIMessageChunk) and chunk.content:\n",
    "                            yield ResponsesAgentStreamEvent(\n",
    "                                **self.create_text_delta(\n",
    "                                    delta=chunk.content, item_id=chunk.id\n",
    "                                ),\n",
    "                            )\n",
    "                    except Exception as exc:\n",
    "                        logger.error(\"Error streaming chunk: %s\", exc)\n",
    "\n",
    "\n",
    "# ----- Export model -----\n",
    "mlflow.langchain.autolog()\n",
    "AGENT = LangGraphResponsesAgent(LAKEBASE_INSTANCE_NAME)\n",
    "mlflow.models.set_model(AGENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36beb42b-d89b-4bde-adde-2509bcc03028",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from agent import AGENT\n",
    "\n",
    "result = AGENT.predict(\n",
    "    {\n",
    "        \"input\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Who committed the latest malware threat?\",\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "print(result.model_dump(exclude_none=True))\n",
    "thread_id = result.custom_outputs[\"thread_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d011adc9-c127-4a57-b805-d3172c65d995",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Message 2, include thread ID and notice how agent remembers context from previous predict message\n",
    "response2 = AGENT.predict(\n",
    "    {\n",
    "        \"input\": [{\"role\": \"user\", \"content\": \"Who was just mentioned?\"}],\n",
    "        \"custom_inputs\": {\"thread_id\": thread_id},\n",
    "    }\n",
    ")\n",
    "print(\"Response 2:\", response2.model_dump(exclude_none=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37fef865-8ca5-4d0f-83a6-657b3edccf65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Determine Databricks resources to specify for automatic auth passthrough at deployment time\n",
    "import mlflow\n",
    "from databricks_langchain import VectorSearchRetrieverTool\n",
    "from mlflow.models.resources import (\n",
    "    DatabricksFunction,\n",
    "    DatabricksServingEndpoint,\n",
    "    DatabricksLakebase,\n",
    "    DatabricksVectorSearchIndex,\n",
    ")  # we are adding DatabricksLakebase resource type\n",
    "from mlflow.models.auth_policy import AuthPolicy, SystemAuthPolicy, UserAuthPolicy\n",
    "from unitycatalog.ai.langchain.toolkit import UnityCatalogTool\n",
    "from agent import LLM_ENDPOINT_NAME, LAKEBASE_INSTANCE_NAME, tools\n",
    "from pkg_resources import get_distribution\n",
    "\n",
    "# TODO: Manually include additional underlying resources if needed and update values for endpoint/lakebase\n",
    "resources = [\n",
    "    DatabricksServingEndpoint(endpoint_name=LLM_ENDPOINT_NAME),\n",
    "    DatabricksLakebase(database_instance_name=LAKEBASE_INSTANCE_NAME),\n",
    "]\n",
    "for tool in tools:\n",
    "    if isinstance(tool, VectorSearchRetrieverTool):\n",
    "        resources.extend(tool.resources)\n",
    "    elif isinstance(tool, UnityCatalogTool):\n",
    "        resources.append(DatabricksFunction(function_name=tool.uc_function_name))\n",
    "\n",
    "# System policy: resources accessed with system credentials\n",
    "system_policy = SystemAuthPolicy(resources=resources)\n",
    "\n",
    "# User policy: API scopes for OBO access\n",
    "api_scopes = [\n",
    "    \"sql.statement-execution\",\n",
    "    \"mcp.genie\",\n",
    "    \"mcp.external\",\n",
    "    \"catalog.connections\",\n",
    "    \"mcp.vectorsearch\",\n",
    "    \"vectorsearch.vector-search-indexes\",\n",
    "    \"iam.current-user:read\",\n",
    "    \"sql.warehouses\",\n",
    "    \"dashboards.genie\",\n",
    "    \"serving.serving-endpoints\",\n",
    "    \"iam.access-control:read\",\n",
    "    \"apps.apps\",\n",
    "    \"mcp.functions\",\n",
    "    \"vectorsearch.vector-search-endpoints\",\n",
    "]\n",
    "user_policy = UserAuthPolicy(api_scopes=api_scopes)\n",
    "\n",
    "input_example = {\n",
    "    \"input\": [{\"role\": \"user\", \"content\": \"What is an LLM agent?\"}],\n",
    "    \"custom_inputs\": {\"thread_id\": \"example-thread-123\"},\n",
    "}\n",
    "\n",
    "with mlflow.start_run():\n",
    "    logged_agent_info = mlflow.pyfunc.log_model(\n",
    "        name=\"agent\",\n",
    "        python_model=\"agent.py\",\n",
    "        input_example=input_example,\n",
    "        pip_requirements=[\n",
    "            f\"databricks-langchain[memory]=={get_distribution('databricks-langchain[memory]').version}\",\n",
    "        ],\n",
    "        resources=resources,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a986456a-f881-46e3-99fe-99b0ef7758ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.models.predict(\n",
    "    model_uri=f\"runs:/{logged_agent_info.run_id}/agent\",\n",
    "    input_data=input_example,\n",
    "    env_manager=\"uv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc29adc0-2738-4fbb-8e0f-92e93bd50617",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# TODO: define the catalog, schema, and model name for your UC model\n",
    "UC_MODEL_NAME = f\"{catalog}.{schema}.{model}\"\n",
    "\n",
    "# register the model to UC\n",
    "uc_registered_model_info = mlflow.register_model(\n",
    "    model_uri=logged_agent_info.model_uri,\n",
    "    name=UC_MODEL_NAME,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9be4813e-2d48-4dff-b900-d9d7c9d2d013",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks import agents\n",
    "\n",
    "agents.deploy(\n",
    "    UC_MODEL_NAME,\n",
    "    uc_registered_model_info.version,\n",
    "    environment_vars={\n",
    "        \"DATABRICKS_HOST\": \"{{secrets/secrets_scope/DATABRICKS_HOST}}\",\n",
    "        \"DATABRICKS_CLIENT_ID\": \"{{secrets/secrets_scope/DATABRICKS_CLIENT_ID}}\",\n",
    "        \"DATABRICKS_CLIENT_SECRET\": \"{{secrets/secrets_scope/DATABRICKS_CLIENT_SECRET}}\",\n",
    "    },\n",
    "    tags={\"endpointSource\": \"playground\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d140d2fc-c5ce-42ad-b45d-a269de8b7507",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks import agents\n",
    "\n",
    "# Note that  can specify individual users or groups.\n",
    "agents.set_permissions(\n",
    "    model_name=UC_MODEL_NAME,\n",
    "    users=[\"users\"],\n",
    "    permission_level=agents.PermissionLevel.CAN_QUERY,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8af7987e-5dbe-4fa3-ae99-a7ca0f0578ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Next steps\n",
    "After your agent is deployed, you can chat with it in AI playground to perform additional checks, share it with SMEs in your organization for feedback, or embed it in a production application. See docs for details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65fc3451-8d75-47ff-82e0-ed29102f09ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from databricks.sdk.service.serving import EndpointStateReady, EndpointStateConfigUpdate\n",
    "from databricks.sdk import WorkspaceClient\n",
    "\n",
    "endpoint_name: str = f\"agents_{catalog}-{schema}-{model}\"\n",
    "print(\"\\nWaiting for endpoint to deploy.  This can take 10 - 20 minutes.\", end=\"\")\n",
    "w = WorkspaceClient()\n",
    "while (\n",
    "    w.serving_endpoints.get(endpoint_name).state.ready == EndpointStateReady.NOT_READY\n",
    "    or w.serving_endpoints.get(endpoint_name).state.config_update\n",
    "    == EndpointStateConfigUpdate.IN_PROGRESS\n",
    "):\n",
    "    print(\".\", end=\"\")\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc3c7c50-a349-4cbf-9c28-b6b9a8614c65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "\n",
    "w = WorkspaceClient()\n",
    "ep = w.serving_endpoints.get(endpoint_name)\n",
    "print(ep.task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bac4a02e-42c0-4479-a657-4c48ba3dc6aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.deployments import get_deploy_client\n",
    "\n",
    "w = WorkspaceClient()\n",
    "endpoint_name: str = f\"agents_{catalog}-{schema}-{model}\"\n",
    "res = get_deploy_client(\"databricks\").predict(\n",
    "    endpoint=endpoint_name,\n",
    "    inputs={\n",
    "        \"input\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Who did I just mention?\",\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 400,\n",
    "        \"custom_inputs\": {\"thread_id\": thread_id},\n",
    "        \"temperature\": 0.1,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d6a6bb4-a944-40db-9726-5e09adf4fe82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if \"output\" in res:\n",
    "    print(res[\"output\"][0][\"content\"][-1][\"text\"])"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2,
    "widgetLayout": []
   },
   "notebookName": "02-lakebase-langgraph-checkpointer-agent",
   "widgets": {
    "DATABRICKS_CLIENT_ID": {
     "currentValue": "",
     "nuid": "18a2b9fc-2a9d-4b4a-9745-a987f8273c27",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "DATABRICKS_CLIENT_ID",
      "name": "DATABRICKS_CLIENT_ID",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "DATABRICKS_CLIENT_ID",
      "name": "DATABRICKS_CLIENT_ID",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "DATABRICKS_CLIENT_SECRET": {
     "currentValue": "",
     "nuid": "f336e7aa-427b-40a8-9abd-d4b99be576b8",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "DATABRICKS_CLIENT_SECRET",
      "name": "DATABRICKS_CLIENT_SECRET",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "DATABRICKS_CLIENT_SECRET",
      "name": "DATABRICKS_CLIENT_SECRET",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "catalog": {
     "currentValue": "",
     "nuid": "2b1943f2-92cd-4f7a-a824-a27ce3498e62",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "bo_cheng_dnb_demos",
      "label": "catalog",
      "name": "catalog",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "bo_cheng_dnb_demos",
      "label": "catalog",
      "name": "catalog",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "model": {
     "currentValue": "",
     "nuid": "fe1c81e8-14a0-417e-ac97-d1e2dedace82",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "memory_agent",
      "label": "model",
      "name": "model",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "memory_agent",
      "label": "model",
      "name": "model",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "schema": {
     "currentValue": "",
     "nuid": "62018a9f-5147-4245-8c23-b83350be3cbb",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "agents",
      "label": "schema",
      "name": "schema",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "agents",
      "label": "schema",
      "name": "schema",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "secret_scope": {
     "currentValue": "dbdemos",
     "nuid": "a3917bf5-f120-4e11-82a8-fd1ea3803bd6",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "dbdemos",
      "label": "secret_scope",
      "name": "secret_scope",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "dbdemos",
      "label": "secret_scope",
      "name": "secret_scope",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}